{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Import useful libs"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import numpy as np;\n",
                "import pandas as pd;\n",
                "import matplotlib.pyplot as plt;\n",
                "import geopandas as gpd"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Read Auxiliar CSVs"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "anotate_codes = pd.read_csv('./datasets/anotate_codes.csv')\n",
                "claim_codes = pd.read_csv('./datasets/claim_codes.csv')\n",
                "commod_type_codes = pd.read_csv('./datasets/commod_type_codes.csv')\n",
                "commodity_codes = pd.read_csv('./datasets/commodity_codes.csv')\n",
                "concen_codes = pd.read_csv('./datasets/concen_codes.csv')\n",
                "confmethod_codes = pd.read_csv('./datasets/confmethod_codes.csv')\n",
                "country_codes = pd.read_csv('./datasets/country_codes.csv')\n",
                "determin_codes = pd.read_csv('./datasets/determin_codes.csv')\n",
                "diisttype_codes = pd.read_csv('./datasets/disttype_codes.csv')\n",
                "extract_codes = pd.read_csv('./datasets/extract_codes.csv')\n",
                "lab_codes = pd.read_csv('./datasets/lab_codes.csv')\n",
                "mean_codes = pd.read_csv('./datasets/mean_codes.csv')\n",
                "origin_codes = pd.read_csv('./datasets/origin_codes.csv')\n",
                "pest_codes = pd.read_csv('./datasets/pest_codes.csv')\n",
                "quantitate_codes = pd.read_csv('./datasets/quantitate_codes.csv')\n",
                "state_codes = pd.read_csv('./datasets/state_codes.csv')\n",
                "test_class_codes = pd.read_csv('./datasets/test_class_codes.csv')\n",
                "tolerance_codes = pd.read_csv('./datasets/tolerance_codes.csv')\n",
                "us_states = pd.read_csv('./datasets/us_states.csv')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Read Samples from all years"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "samples_colums_labels = ('sample_pk','state', 'year', 'month', 'day', 'site', 'commod', 'source_id', 'variety', 'origin', 'country', 'disttype', 'commtype', 'claim', 'quantity', 'growst', 'packst', 'diistst');\n",
                "\n",
                "samples_15 = pd.read_csv('./datasets/database/2015PDPDatabase/PDP15Samples.txt', delimiter=\"|\", names=samples_colums_labels);\n",
                "samples_16 = pd.read_csv('./datasets/database/2016PDPDatabase/PDP16Samples.txt', delimiter=\"|\", names=samples_colums_labels);\n",
                "samples_17 = pd.read_csv('./datasets/database/2017PDPDatabase/PDP17Samples.txt', delimiter=\"|\", names=samples_colums_labels);\n",
                "samples_18 = pd.read_csv('./datasets/database/2018PDPDatabase/PDP18Samples.txt', delimiter=\"|\", names=samples_colums_labels);\n",
                "samples_19 = pd.read_csv('./datasets/database/2019PDPDatabase/PDP19Samples.txt', delimiter=\"|\", names=samples_colums_labels);\n",
                "\n",
                "# Remove imported products\n",
                "samples_15 = samples_15[samples_15['origin']==1]\n",
                "samples_16 = samples_16[samples_16['origin']==1]\n",
                "samples_17 = samples_17[samples_17['origin']==1]\n",
                "samples_18 = samples_18[samples_18['origin']==1]\n",
                "samples_19 = samples_19[samples_19['origin']==1]\n",
                "\n",
                "# Remove unnecessary columns\n",
                "samples_15.drop(columns=['country', 'growst', 'packst', 'diistst'], inplace = True) \n",
                "samples_16.drop(columns=['country', 'growst', 'packst', 'diistst'], inplace = True) \n",
                "samples_17.drop(columns=['country', 'growst', 'packst', 'diistst'], inplace = True) \n",
                "samples_18.drop(columns=['country', 'growst', 'packst', 'diistst'], inplace = True) \n",
                "samples_19.drop(columns=['country', 'growst', 'packst', 'diistst'], inplace = True) "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Read Results of all years"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "results_colums_labels = ('sample_pk','commod', 'commtype', 'lab', 'pestcode', 'testclass', 'concen', 'lod', 'conunit', 'confmethod', 'confmethod2', 'annotate', 'quantitate', 'mean', 'extract', 'determin');\n",
                "results_15 = pd.read_csv('./datasets/database/2015PDPDatabase/PDP15Results.txt', delimiter=\"|\", names=results_colums_labels);\n",
                "results_16 = pd.read_csv('./datasets/database/2016PDPDatabase/PDP16Results.txt', delimiter=\"|\", names=results_colums_labels);\n",
                "results_17 = pd.read_csv('./datasets/database/2017PDPDatabase/PDP17Results.txt', delimiter=\"|\", names=results_colums_labels);\n",
                "results_18 = pd.read_csv('./datasets/database/2018PDPDatabase/PDP18Results.txt', delimiter=\"|\", names=results_colums_labels);\n",
                "results_19 = pd.read_csv('./datasets/database/2019PDPDatabase/PDP19Results.txt', delimiter=\"|\", names=results_colums_labels);"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Join results and samples CSVs"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "results_join_samples_15 = results_15.merge(samples_15,on='sample_pk',how='inner').drop(columns=['commod_y', 'commtype_y']).rename(columns={'commod_x': 'commod', 'commtype_x':'commtype'})\n",
                "results_join_samples_16 = results_16.merge(samples_16,on='sample_pk',how='inner').drop(columns=['commod_y', 'commtype_y']).rename(columns={'commod_x': 'commod', 'commtype_x':'commtype'})\n",
                "results_join_samples_17 = results_17.merge(samples_17,on='sample_pk',how='inner').drop(columns=['commod_y', 'commtype_y']).rename(columns={'commod_x': 'commod', 'commtype_x':'commtype'})\n",
                "results_join_samples_18 = results_18.merge(samples_18,on='sample_pk',how='inner').drop(columns=['commod_y', 'commtype_y']).rename(columns={'commod_x': 'commod', 'commtype_x':'commtype'})\n",
                "results_join_samples_19 = results_19.merge(samples_19,on='sample_pk',how='inner').drop(columns=['commod_y', 'commtype_y']).rename(columns={'commod_x': 'commod', 'commtype_x':'commtype'})"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "results_join_samples_15 = results_join_samples_15[~results_join_samples_15['concen'].isna()]\n",
                "results_join_samples_16 = results_join_samples_16[~results_join_samples_16['concen'].isna()]\n",
                "results_join_samples_17 = results_join_samples_17[~results_join_samples_17['concen'].isna()]\n",
                "results_join_samples_18 = results_join_samples_18[~results_join_samples_18['concen'].isna()]\n",
                "results_join_samples_19 = results_join_samples_19[~results_join_samples_19['concen'].isna()]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "results_join_samples_17"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Eval each pesticide's presence in all years"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def get_pest_concen_mean (df):\n",
                "  index_name = 'concen_' + str(df.loc[:, 'year'].iloc[0])\n",
                "  pest_concen_not_null = df[~df['concen'].isna()]\n",
                "  \n",
                "  pest_concen_mean = pest_concen_not_null[['pestcode', 'concen']].groupby(['pestcode'])['concen'].mean().rename_axis(['pestcode']).reset_index(name=index_name)\n",
                "  \n",
                "  return pest_concen_mean\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "pest_concen_mean_15 = get_pest_concen_mean(results_join_samples_15)\n",
                "pest_concen_mean_16 = get_pest_concen_mean(results_join_samples_16)\n",
                "pest_concen_mean_17 = get_pest_concen_mean(results_join_samples_17)\n",
                "pest_concen_mean_18 = get_pest_concen_mean(results_join_samples_18)\n",
                "pest_concen_mean_19 = get_pest_concen_mean(results_join_samples_19)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "pest_concen_mean_all_years = pest_concen_mean_15.merge(pest_concen_mean_16, on='pestcode', how='inner').merge(pest_concen_mean_17, on='pestcode', how='inner').merge(pest_concen_mean_18, on='pestcode', how='inner').merge(pest_concen_mean_19, on='pestcode', how='inner')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "pest_concen_mean_all_years"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "only_values = pest_concen_mean_all_years.loc[:,'concen_15':]\n",
                "only_values_T = only_values.T\n",
                "only_values_T.columns=pest_concen_mean_all_years['pestcode']"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "only_values_T"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plt.figure()\n",
                "\n",
                "# Select only a subset because there are too many pesticides\n",
                "only_values_T.iloc[:,50:55].plot(figsize=(10,10))\n",
                "only_values_T.loc[:,['024', '070']].plot(figsize=(10,10))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Get only states and commodities with concentration values in all years"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def get_state_commod_concen_mean (df):\n",
                "  pest_concen_not_null = df[~df['concen'].isna()]\n",
                "  \n",
                "  concen_state_commod_mean = pest_concen_not_null[['year','pestcode', 'state', 'commod', 'concen', 'lod']].groupby(['year', 'state', 'commod', 'pestcode', 'lod'])['concen'].mean().rename_axis(['year', 'state', 'commod', 'pestcode', 'lod']).reset_index(name='concen').sort_values('state')\n",
                "  \n",
                "  return concen_state_commod_mean.merge(us_states, on='state', how='inner')\n",
                "\n",
                "def select_pest_commod (df, c, p):\n",
                "    return df[(df['pestcode']==p) & (df['commod']==c)]\n",
                "    \n",
                "def colorize_concen (row):\n",
                "  if row['concen']>row['lod']:\n",
                "    return '#C62828'\n",
                "  if row['concen']<=row['lod']:\n",
                "    return '#283593'\n",
                "\n",
                "def get_commod_state_concen_colors(df, c, p):\n",
                "  df_result = select_pest_commod(df, c, p)\n",
                "  colors_column = df_result.apply(lambda row: colorize_concen(row), axis=1)\n",
                "  try:\n",
                "    df_result['mapcolor'] = colors_column\n",
                "  except:\n",
                "    print('Um dos valores informados nÃ£o existe na tabela do ano ' + str(df.loc[0]['year']))\n",
                "  return df_result\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "concen_state_commod_mean_15 = get_state_commod_concen_mean(results_join_samples_15)\n",
                "concen_state_commod_mean_16 = get_state_commod_concen_mean(results_join_samples_16)\n",
                "concen_state_commod_mean_17 = get_state_commod_concen_mean(results_join_samples_17)\n",
                "concen_state_commod_mean_18 = get_state_commod_concen_mean(results_join_samples_18)\n",
                "concen_state_commod_mean_19 = get_state_commod_concen_mean(results_join_samples_19)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "concen_state_commod_mean_17[(concen_state_commod_mean_17['concen']\n",
                "<=concen_state_commod_mean_17['lod'])]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "commod_state_concen_colors_15 = get_commod_state_concen_colors(concen_state_commod_mean_15, 'AP', 'AKD')\n",
                "commod_state_concen_colors_16 = get_commod_state_concen_colors(concen_state_commod_mean_16, 'SP', '781')\n",
                "commod_state_concen_colors_17 = get_commod_state_concen_colors(concen_state_commod_mean_17, 'LT', '134')\n",
                "commod_state_concen_colors_18 = get_commod_state_concen_colors(concen_state_commod_mean_18, 'AP', 'AKD')\n",
                "commod_state_concen_colors_19 = get_commod_state_concen_colors(concen_state_commod_mean_19, 'AS', 'AKD')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Plot pesticide concentration per commodity per state"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "gpd.GeoDataFrame(commod_state_concen_colors_17, geometry=gpd.points_from_xy(commod_state_concen_colors_17.longitude, commod_state_concen_colors_17.latitude))\n",
                "states = gpd.read_file('shapes/usa-states-census-2014.shp')\n",
                "states = states.to_crs(\"EPSG:3395\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "states_colors = commod_state_concen_colors_17[['state', 'mapcolor']]\n",
                "teste2 = states.rename(columns={'STUSPS': 'state'}).merge(states_colors, on='state', how='left')\n",
                "teste3 = teste2.fillna('#fffacf')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "fig, ax = plt.subplots(figsize=(15,15))\n",
                "states.apply(lambda x: ax.annotate(s=x.NAME, xy=x.geometry.centroid.coords[0], ha='center', fontsize=5),axis=1);\n",
                "states.plot(ax=ax, figsize=(12,12), color=teste3['mapcolor'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Eval each pesticide's presence per commodity in all years"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 137,
            "source": [
                "def get_commod_concen_mean (df):\n",
                "  index_name = 'concen_' + str(df.loc[:, 'year'].iloc[0])\n",
                "  pest_concen_not_null = df[~df['concen'].isna()]\n",
                "  \n",
                "  pest_concen_commod_mean = pest_concen_not_null[['pestcode', 'commod', 'concen']].groupby(['commod', 'pestcode'])['concen'].mean().rename_axis(['commod', 'pestcode']).reset_index(name=index_name)\n",
                "  \n",
                "  return pest_concen_commod_mean\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 142,
            "source": [
                "concen_commod_mean_15 = get_commod_concen_mean(results_join_samples_15)\n",
                "concen_commod_mean_16 = get_commod_concen_mean(results_join_samples_16)\n",
                "concen_commod_mean_17 = get_commod_concen_mean(results_join_samples_17)\n",
                "concen_commod_mean_18 = get_commod_concen_mean(results_join_samples_18)\n",
                "concen_commod_mean_19 = get_commod_concen_mean(results_join_samples_19)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit"
        },
        "interpreter": {
            "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}